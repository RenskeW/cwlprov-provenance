{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARQL queries of CWLProv provenance files\n",
    "This document provides an overview of different SPARQL queries, together with their (expected) result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules & queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rdflib\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path(os.getcwd())\n",
    "queries_dir = cwd / 'queries'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(rdf_file, query_file):\n",
    "    \"\"\"\n",
    "    file = RDF file; query_file = path to sparql query file.\n",
    "    \"\"\"\n",
    "    g = rdflib.Graph()\n",
    "    g.parse(rdf_file)\n",
    "    with open(query_file, 'r')  as f:\n",
    "        query = f.read()\n",
    "        \n",
    "    print(f\"SPARQL QUERY IS:\\n{query}\")\n",
    "    \n",
    "    qres = g.query(query)\n",
    "    \n",
    "    results = pd.DataFrame(qres.bindings).applymap(str).rename(columns=str)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARQL queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the Docker images used in this workflow run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arcp://uuid,a914217a-5cd2-457d-85cc-7472eeb17bfd/workflow/packed.cwl#main/generate_pc7 used amancevice/pandas:1.3.4-slim\n"
     ]
    }
   ],
   "source": [
    "provenance_file = cwd / \"labels_wf_primary_cwlprov.ttl\" # replace this with provenance file of full workflow run\n",
    "extract_images_query = queries_dir / \"docker_images.sparql\"\n",
    "response = run_query(provenance_file, extract_images_query)\n",
    "for row in response:\n",
    "    print(f\"{row.step} used {row.image}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List every entity that has a DOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<doi>\n",
      "<doi>\n"
     ]
    }
   ],
   "source": [
    "provenance_file = cwd / 'data_ann_ex1_primary.cwlprov.ttl' # replace this with provenance file of full workflow run\n",
    "extract_doi_query = queries_dir / 'dois.sparql'\n",
    "response = run_query(provenance_file, extract_doi_query)\n",
    "for row in response:\n",
    "    print(f\"{row.doi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the formats of all files for which this is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sabdab_summary_all_20220527.tsv has format https://www.iana.org/assignments/media-types/text/tab-separated-values\n",
      "7mb7.cif has format http://edamontology.org/format_1477\n",
      "7zxf.cif has format http://edamontology.org/format_1477\n"
     ]
    }
   ],
   "source": [
    "provenance_file = cwd / 'data_ann_ex2_primary.cwlprov.ttl'\n",
    "extract_format_query = queries_dir / 'format.sparql'\n",
    "response = run_query(provenance_file, extract_format_query)\n",
    "for row in response:\n",
    "    print(f\"{row.basename} has format {row.format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries of emulated provenance file\n",
    "Emulated RDF graph of epitope prediction workflow run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_provenance = cwd / 'niaa_wf_run/primary.cwlprov.ttl'\n",
    "extract_citations_query = queries_dir / 'dois.sparql'\n",
    "response = run_query(workflow_provenance, extract_citations_query)\n",
    "for row in response:\n",
    "    print(f\"{row.doi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract description of workflow run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is:\n",
      "PREFIX s: <http://schema.org/>\n",
      "PREFIX wfprov: <http://purl.org/wf4ever/wfprov#> \n",
      "\n",
      "SELECT ?desc\n",
      "\n",
      "WHERE {\n",
      "    ?id a wfprov:WorkflowRun .\n",
      "    ?id s:description ?desc .\n",
      "}\n",
      "Description of workflow run: Demonstration run of epitope prediction workflow. Some steps are emulated, so the results of the workflow are not yet biologically meaningful.\n"
     ]
    }
   ],
   "source": [
    "workflow_provenance = cwd / 'niaa_wf_run/primary.cwlprov.ttl'\n",
    "extract_wf_desc_query = queries_dir / 'execution_desc.sparql'\n",
    "response = run_query(workflow_provenance, extract_wf_desc_query)\n",
    "for row in response:\n",
    "    print(f\"Description of workflow run: {row.desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract metadata of workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARQL QUERY IS:\n",
      "PREFIX s: <http://schema.org/>\n",
      "PREFIX wfdesc: <http://purl.org/wf4ever/wfdesc#> \n",
      "\n",
      "SELECT ?id ?doc ?intent\n",
      "\n",
      "WHERE {\n",
      "    ?id a wfdesc:Workflow .\n",
      "    ?id s:description ?doc .\n",
      "    ?id s:featureList ?intent .\n",
      "}\n",
      "Doc field of workflow: This workflow calculates input features and labels which are used to train a deep learning model for epitope prediction.\n",
      "Intent field of workflow: http://edamontology.org/operation_2423\n",
      "<rdflib.plugins.sparql.processor.SPARQLResult object at 0x7ff430be2ac0>\n"
     ]
    }
   ],
   "source": [
    "workflow_provenance = cwd / 'niaa_wf_run/primary.cwlprov.ttl'\n",
    "extract_wf_annot_query = queries_dir / 'wf_annotations.sparql'\n",
    "response = run_query(workflow_provenance, extract_wf_annot_query)\n",
    "for row in response:\n",
    "    print(f\"Doc field of workflbow: {row.doc}\\nIntent field of workflow: {row.intent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the steps of the workflow, with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARQL QUERY IS:\n",
      "PREFIX s: <http://schema.org/>\n",
      "PREFIX wfdesc: <http://purl.org/wf4ever/wfdesc#> \n",
      "\n",
      "SELECT ?step_id ?doc ?label ?clt\n",
      "\n",
      "WHERE {\n",
      "    ?wf a wfdesc:Workflow .\n",
      "    ?wf wfdesc:hasSubProcess ?step_id .\n",
      "    OPTIONAL { ?step_id s:description ?doc . } .\n",
      "    OPTIONAL { ?step_id s:name ?label . } .\n",
      "    OPTIONAL { ?step_id wfdesc:hasSubProcess ?clt . } .\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "workflow_provenance = cwd / 'niaa_wf_run/primary.cwlprov.ttl'\n",
    "extract_wf_steps_query = queries_dir / 'wf_steps.sparql'\n",
    "response = run_query(workflow_provenance, extract_wf_steps_query)\n",
    "# for row in response:\n",
    "#     print(f\"Step: {row.step_id}\")\n",
    "response.to_csv(cwd / 'results/step_descriptions.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the input parameters of 1 particular step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARQL QUERY IS:\n",
      "PREFIX s: <http://schema.org/>\n",
      "PREFIX cwlprov: <https://w3id.org/cwl/prov#>\n",
      "PREFIX prov: <http://www.w3.org/ns/prov#>\n",
      "PREFIX wfdesc: <http://purl.org/wf4ever/wfdesc#> \n",
      "\n",
      "SELECT DISTINCT ?step_input\n",
      "\n",
      "WHERE {\n",
      "    ?wf wfdesc:hasSubProcess <arcp://uuid,eb41f41c-d7b4-4999-9ce9-719fdc8c12b1/workflow/packed.cwl#main/combine_labels> .\n",
      "    OPTIONAL { <arcp://uuid,eb41f41c-d7b4-4999-9ce9-719fdc8c12b1/workflow/packed.cwl#main/combine_labels> wfdesc:hasInput ?step_input } .\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "workflow_provenance = cwd / 'niaa_wf_run/primary.cwlprov.ttl'\n",
    "extract_step_params_query = queries_dir /'step_metadata.sparql'\n",
    "response = run_query(workflow_provenance, extract_step_params_query)\n",
    "response.to_csv(cwd / 'results/step_params.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c62268e61c4afe27ae9b7b489ddf7635acdf5c92443b5735506dfc7de80cd647"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
